{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "import models\n",
    "import draw\n",
    "import tools\n",
    "\n",
    "random_state = 12314\n",
    "torch.manual_seed(random_state) # cpu\n",
    "np.random.seed(random_state)    # numpy\n",
    "random.seed(random_state)       # random and transforms\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '0,1,2,3'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_GPU = torch.cuda.device_count()\n",
    "    print(f\"GPU 数量: {num_GPU}\")\n",
    "else:\n",
    "    num_GPU = 1\n",
    "    \n",
    "print(f\"运行平台: {device}\") \n",
    "root_path = os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load synthetic geologic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "dataset_name = \"0108-128x256x256\"\n",
    "dataset_path = os.path.join(root_path, \"datasets\", dataset_name)\n",
    "                            \n",
    "samples_train = np.load(os.path.join(dataset_path, 'samples_train.npy'), allow_pickle=True)\n",
    "samples_valid = np.load(os.path.join(dataset_path, 'samples_valid.npy'), allow_pickle=True)\n",
    "\n",
    "print(f\"训练样本数量: {len(samples_train)}\")\n",
    "print(f\"验证样本数量: {len(samples_valid)}\")\n",
    "\n",
    "train_sample_path = os.path.join(dataset_path, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of data simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshape = (128,128,128)\n",
    "num_hrzs_list=[2]\n",
    "bit=256\n",
    "mask_grp_sel=[4,None]\n",
    "bit_rate=2\n",
    "sample_rate_list=[50, 100]\n",
    "fault_range=1\n",
    "bit_mute = 85\n",
    "norm=utils.min_max_norm\n",
    "use_normal=False\n",
    "if use_normal:\n",
    "    input_attr_list = [\"scalar\", \"normal\", \"fault\"]\n",
    "else:\n",
    "    input_attr_list = [\"scalar\", \"fault\"] \n",
    "output_attr_list = [\"rgt\"]\n",
    "\n",
    "print(f\"输入属性:{input_attr_list}\")\n",
    "print(f\"目标属性:{output_attr_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic structural data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  utils.build_dataset(inshape, samples_train, train_sample_path, 'Valid',\n",
    "                            num_hrzs_list=num_hrzs_list,\n",
    "                            bit=bit,\n",
    "                            mask_grp_sel=mask_grp_sel,\n",
    "                            bit_rate=bit_rate,\n",
    "                            sample_rate_list=sample_rate_list,\n",
    "                            fault_range=fault_range, \n",
    "                            bit_mute = bit_mute,\n",
    "                            norm=norm, \n",
    "                            point_set=True, use_normal=use_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_samples = [train_data[i] for i in range(30,50)]\n",
    "k = 15\n",
    "gt = batch_samples[k]['rgt'][0]\n",
    "fl = batch_samples[k]['fault'][0]\n",
    "ps = batch_samples[k]['point_set_scalar']\n",
    "fm = batch_samples[k]['mask'][0]\n",
    "nps = batch_samples[k]['point_set_scalar']\n",
    "fps = batch_samples[k]['point_set_fault']\n",
    "cvs = draw.get_horizon_scalar(nps, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw.draw_slice_line_surf(fl, \n",
    "                     x_slices=[30], y_slices=[30], z_slices=[120], \n",
    "                     points=nps, points2=fps, \n",
    "                     smap='jet', smin=np.min(gt), smax=np.max(gt),\n",
    "                     cmap='fault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  utils.build_dataset(inshape, samples_train, train_sample_path, 'Train',\n",
    "                            num_hrzs_list=num_hrzs_list,\n",
    "                            bit=bit,\n",
    "                            mask_grp_sel=mask_grp_sel,\n",
    "                            bit_rate=bit_rate,\n",
    "                            sample_rate_list=sample_rate_list,\n",
    "                            fault_range=fault_range, \n",
    "                            bit_mute = bit_mute, \n",
    "                            norm=norm, use_normal=use_normal)\n",
    "\n",
    "valid_data =  utils.build_dataset(inshape, samples_valid, train_sample_path, 'Valid',\n",
    "                            num_hrzs_list=num_hrzs_list,\n",
    "                            bit=bit,\n",
    "                            mask_grp_sel=mask_grp_sel,\n",
    "                            bit_rate=bit_rate,\n",
    "                            sample_rate_list=sample_rate_list,\n",
    "                            fault_range=fault_range, \n",
    "                            bit_mute = bit_mute, \n",
    "                            norm=norm, use_normal=use_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络\n",
    "param_model = {}\n",
    "param_model['network'] = \"ISMNet\"\n",
    "param_model['input_channels'] = 1+1\n",
    "if use_normal:\n",
    "    param_model['input_channels'] += 3\n",
    "param_model['output_channels'] = 1\n",
    "param_model['inshape'] = inshape\n",
    "\n",
    "model = getattr(models, param_model['network'])(param_model)\n",
    "loss_type = {\"mae\":0.24, \"ms-ssim\":0.84}\n",
    "loss_name = '+'.join([f\"{'{:.2f}'.format(value)}*{key}\" for key, value in loss_type.items()])\n",
    "\n",
    "session_name = '-'.join([param_model['network'], \"dataset_\"+dataset_name, loss_name])\n",
    "if use_normal:\n",
    "    session_name = '-'.join([session_name, \"orientation\"])  \n",
    "    \n",
    "# 并行模式\n",
    "if num_GPU > 1:\n",
    "    print(f\"多核模式\")\n",
    "    model = torch.nn.DataParallel(model, device_ids=range(num_GPU)).to(device)\n",
    "else:\n",
    "    print(f\"单核模式\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "# 模型保存路径\n",
    "checkpoint_path = os.path.join('checkpoints', session_name)\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "print(f\"模型读取路径: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练参数\n",
    "param = {}\n",
    "param['model'] = param_model\n",
    "param['epochs'] = 161 # 训练轮数  \n",
    "param['batch_size'] = 2*num_GPU # 批大小\n",
    "param['lr'] = 1e-3 # 学习率         \n",
    "param['optimizer_type'] = 'Adam' # 优化器类型 \n",
    "param['weight_decay'] = 1e-4 # 权重衰减\n",
    "param['decay_type'] = 'ReduceLROnPlateau' # 学习率衰减策略 \n",
    "param['gamma'] = 0.5 # 学习率衰减系数    \n",
    "param['lr_decay'] = 2 # 学习率衰减周期\n",
    "param['loss_type'] = loss_type\n",
    "param['checkpoint_path'] = checkpoint_path\n",
    "param['disp_inter'] = 2 # 显示间隔 \n",
    "param['save_inter'] = 10 # 保存间隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练网络\n",
    "model = utils.train_valid_net(param, model, train_data, valid_data, plot=True, \n",
    "                              device=device, use_normal=use_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_checkpoint_path = os.path.join(\"checkpoints\", \"ISMNet-dataset_0108-128x256x256\")\n",
    "model.load_state_dict(torch.load(os.path.join(load_checkpoint_path, 'checkpoint-best.pth'))['state_dict'])\n",
    "print(f\"模型读取路径: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inshape = (128,128,128)\n",
    "num_hrzs_list=[2]\n",
    "bit=256\n",
    "mask_grp_sel=[2,None]\n",
    "bit_rate=2\n",
    "sample_rate_list=[100]\n",
    "fault_range=1\n",
    "bit_mute=80\n",
    "norm=utils.min_max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data =  utils.build_dataset(inshape, samples_valid[3:4], train_sample_path, 'Valid',\n",
    "                            num_hrzs_list=num_hrzs_list,\n",
    "                            bit=bit,\n",
    "                            mask_grp_sel=mask_grp_sel,\n",
    "                            bit_rate=bit_rate,\n",
    "                            sample_rate_list=sample_rate_list,\n",
    "                            fault_range=fault_range, \n",
    "                            bit_mute = bit_mute, \n",
    "                            norm=norm, use_normal=use_normal,\n",
    "                            point_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_samples = utils.pred(model, test_data, use_normal=use_normal, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k  = 0\n",
    "gt = output_pred_samples[k]['rgt'][0]\n",
    "nps= output_pred_samples[k]['point_set_scalar']\n",
    "fps= output_pred_samples[k]['point_set_fault']\n",
    "mk = output_pred_samples[k]['mask'][0]\n",
    "fl = output_pred_samples[k]['fault'][0]\n",
    "pd = output_pred_samples[k]['pred'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_slice_line_surf(pd, \n",
    "                     x_slices=[20], y_slices=[20], z_slices=[120], \n",
    "                     points=nps, \n",
    "                     points2=fps,\n",
    "                     cmap='model',\n",
    "                     isovol=pd, \n",
    "                     isofs=draw.get_horizon_scalar(nps, pd),\n",
    "                     mute_edge=3,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
