{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "root_path = os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample,num_inline,num_crossline = 128,256,256\n",
    "data_name = \"0108-128x256x256\"\n",
    "dataset_name = \"0108-128x256x256\"\n",
    "# 设置路径\n",
    "\n",
    "raw_data_path = os.path.join(os.path.abspath('..'), \"DATA\", data_name)\n",
    "dataset_path = os.path.join(root_path, \"datasets\", data_name)\n",
    "\n",
    "seis_path = os.path.join(raw_data_path, \"seis\")\n",
    "rgt_path = os.path.join(raw_data_path, \"rgt\")\n",
    "fault_path = os.path.join(raw_data_path, \"fault\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "train_dataset_path = os.path.join(dataset_path, \"data\")\n",
    "if not os.path.exists(train_dataset_path):\n",
    "    os.makedirs(train_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_list = os.listdir(seis_path)\n",
    "data_file_index = [i[0] for i in sorted(enumerate(data_file_list), key=lambda x:int(x[1].split('.')[0]))]\n",
    "data_file_list = [data_file_list[i] for i in data_file_index]\n",
    "num_data_file = len(data_file_list)\n",
    "size = (num_sample,num_inline,num_crossline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = 0\n",
    "train_sample_list = []\n",
    "for index, data_file_name in enumerate(data_file_list):\n",
    "    print(f\"Processing raw data file {index+1}/{num_data_file} ...\")       \n",
    "    \n",
    "    seis_file_path = os.path.join(seis_path, data_file_name)\n",
    "    seis_cube = utils.read_data(size,seis_file_path)\n",
    "\n",
    "    rgt_file_path = os.path.join(rgt_path,str(index)+\".dat\")\n",
    "    rgt_cube = utils.read_data(size,rgt_file_path)\n",
    "\n",
    "    fault_file_path = os.path.join(fault_path,str(index)+\".dat\")\n",
    "    fault_cube = utils.read_data(size,fault_file_path)\n",
    "\n",
    "    sample = {}\n",
    "    sample[\"seis\"] = seis_cube\n",
    "    sample[\"rgt\"] = rgt_cube\n",
    "    sample[\"fault\"] = fault_cube\n",
    "    \n",
    "    sample_file_name = f'sample_{sample_count}.npy'\n",
    "    sample[\"fname\"] = sample_file_name\n",
    "    \n",
    "    np.save(os.path.join(train_dataset_path, sample_file_name), sample)  \n",
    "    train_sample_list.append(sample_file_name)\n",
    "    sample_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集比例\n",
    "train_set_ratio = 0.9\n",
    "\n",
    "num_train_sample = len(train_sample_list)\n",
    "print(f\"样本库总数: {num_train_sample}\")\n",
    "\n",
    "# 混乱数据集\n",
    "random.shuffle(train_sample_list)\n",
    "\n",
    "# 训练集/验证集划分\n",
    "valid_num = int(num_train_sample * (1-train_set_ratio))\n",
    "valid_sample_list = random.sample(train_sample_list, valid_num)\n",
    "\n",
    "samples_train,samples_valid = [],[]\n",
    "\n",
    "for i_sample in train_sample_list[:num_train_sample]:\n",
    "    if i_sample not in valid_sample_list:\n",
    "        samples_train.append(i_sample)\n",
    "    else:\n",
    "        samples_valid.append(i_sample)\n",
    "\n",
    "print(f'训练样本数量：{len(samples_train)}')\n",
    "print(f'验证样本数量：{len(samples_valid)}')\n",
    "np.save(os.path.join(dataset_path, 'samples_train.npy'), samples_train)\n",
    "np.save(os.path.join(dataset_path, 'samples_valid.npy'), samples_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
